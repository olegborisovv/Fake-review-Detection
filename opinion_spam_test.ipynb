{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opinion Spam detection\n",
    "======================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We not only predict if a review is Fake or True but we also predict the class it belongs to (Negative or Positive) .\n",
    "\n",
    "Main idea of predicting whether given review is fake or real is addressed by using pos tagging and BOW(Bag of Words) model , First let us prepare the data to suffice the experiment needs. \n",
    "\n",
    "I have classified the reviews into four classes as follows :\n",
    "- Highly positive (1) : The review is marked as positive and it is deceptive .\n",
    "- Positive (2) : A review is marked as positive and it is truly positive .\n",
    "- Negative (3) : A review is marked and negative and it is truly negative .\n",
    "- Highly Negative (4) : A review is marked and negative and it is deceptive ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a review we will predict whether it is a true review or fake one using the following statergy:\n",
    "- If the review falls into 2nd or 3rd class then it is true review (Review is NOT FAKE) \n",
    "- If the review falls into 1st or 4th class then the review is fake ! (Review is FAKE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a summary of the libraries used \n",
    "- os : As we are working with txt files, we'll use this lib to get the file names and to work with them .\n",
    "- pandas : For creating data frames and manipulating .\n",
    "- nltk :  For removing stopwords , tokenizing , parts of speech tagging and lematization\n",
    "- gensim for creating the corpus , implementing bag of words , and matutils of gensim to convert corpus to sparse form. \n",
    "- sklearn for GridSearchCV, for splitting data , Random Forest and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaitanya/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/chaitanya/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from gensim import matutils,corpora, models\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the data , get into the root directory **`op_spam_v1.4`**  and execute the following shell scripting commands to get all the positive reviews into one folder and all negative reviews into another folder ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command get all the txt files in the ** `negative_polariy`** folder into one folder and deletes all the folders except the root folder (**`negative_polarity`**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! cd negative_polarity && find . -type f -print0 | xargs -0 -I file mv --backup=numbered file . && rm -rf truthful_from_Web && rm -rf deceptive_from_MTurk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command get all the txt files in the ** `positive_polariy`** folder into one folder and deletes all the folders except the root folder (**`positive_polarity`**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! cd positive_polarity && find . -type f -print0 | xargs -0 -I file mv --backup=numbered file . && rm -rf truthful_from_TripAdvisor && rm -rf deceptive_from_MTurk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_list = os.listdir(\"negative_polarity\") # names of all files in the negative_polarity dir into a list\n",
    "positive_list = os.listdir(\"positive_polarity\") # names of all files in the positive_polarity dir into a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A function to create a dataframe with  \"review\" \"labeled_class\" and \"actual_class\"(t or d) as columns .**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(files_list,root_dir,polarity):\n",
    "    labeled_class = []\n",
    "    reviews = []\n",
    "    actual_class =[]\n",
    "    for j in files_list:\n",
    "        labeled_class.append(polarity)\n",
    "        k = str(open(root_dir + '/' + j).read())\n",
    "        reviews.append(k)\n",
    "        actual_class.append(str(j.split('_')[0]))\n",
    "    data = pd.DataFrame({'labeled_class':labeled_class,'review':reviews,'actual_class':actual_class})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create seperate data frames for postive and negative reviews **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_df = preprocess(negative_list,'negative_polarity','negative')\n",
    "positive_df = preprocess(positive_list,'positive_polarity','positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_class</th>\n",
       "      <th>labeled_class</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t</td>\n",
       "      <td>negative</td>\n",
       "      <td>Very disappointed in our stay in Chicago Monoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t</td>\n",
       "      <td>negative</td>\n",
       "      <td>I just had a conference there. They have bed b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>negative</td>\n",
       "      <td>Over-hyped and over-priced. The fact that they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t</td>\n",
       "      <td>negative</td>\n",
       "      <td>My family of four went to a convention and sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t</td>\n",
       "      <td>negative</td>\n",
       "      <td>Beautiful historic hotel -- and since I'm in h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual_class labeled_class  \\\n",
       "0            t      negative   \n",
       "1            t      negative   \n",
       "2            t      negative   \n",
       "3            t      negative   \n",
       "4            t      negative   \n",
       "\n",
       "                                              review  \n",
       "0  Very disappointed in our stay in Chicago Monoc...  \n",
       "1  I just had a conference there. They have bed b...  \n",
       "2  Over-hyped and over-priced. The fact that they...  \n",
       "3  My family of four went to a convention and sta...  \n",
       "4  Beautiful historic hotel -- and since I'm in h...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_class</th>\n",
       "      <th>labeled_class</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t</td>\n",
       "      <td>positive</td>\n",
       "      <td>We had a king deluxe room for 2 nights. We res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t</td>\n",
       "      <td>positive</td>\n",
       "      <td>The Swisshotel is awesome. Very high class. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>positive</td>\n",
       "      <td>Having had a great stay at the Monaco last Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t</td>\n",
       "      <td>positive</td>\n",
       "      <td>Simply a nice place to stay... I had a great d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t</td>\n",
       "      <td>positive</td>\n",
       "      <td>Stayed here October 31 through November 5 for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual_class labeled_class  \\\n",
       "0            t      positive   \n",
       "1            t      positive   \n",
       "2            t      positive   \n",
       "3            t      positive   \n",
       "4            t      positive   \n",
       "\n",
       "                                              review  \n",
       "0  We had a king deluxe room for 2 nights. We res...  \n",
       "1  The Swisshotel is awesome. Very high class. It...  \n",
       "2  Having had a great stay at the Monaco last Fal...  \n",
       "3  Simply a nice place to stay... I had a great d...  \n",
       "4  Stayed here October 31 through November 5 for ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following chunk of code adds a column named target which is our variable of interest. First consider the positive reviews data frame .\n",
    "- **(positive + d) : ** If the *actual_class* is marked as **d** , it means that review is highly positive so we assign this to 1  \n",
    "- **(positive + t) : ** If the *actual_class* is marked as **t** , it means that review is truly positve so we assign this to 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = []\n",
    "for i in positive_df.index:\n",
    "    if ((positive_df['labeled_class'][i] == 'positive') & (positive_df['actual_class'][i] == 't')):\n",
    "        target.append(2)\n",
    "    elif ((positive_df['labeled_class'][i] == 'positive') & (positive_df['actual_class'][i] == 'd')):\n",
    "        target.append(1)\n",
    "    else:\n",
    "        print('Error!')\n",
    "positive_df['target'] = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us  consider the negative reviews data frame .\n",
    "- **(negative + t) : ** If the *actual_class* is marked as **t** , it means that review is truly negative so we assign this to 3\n",
    "- **(negative + d) : ** If the *actual_class* is marked as **d** , it means that review is highly negative so we assign this to 4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = []\n",
    "for i in negative_df.index:\n",
    "    if ((negative_df['labeled_class'][i] == 'negative') & (negative_df['actual_class'][i] == 't')):\n",
    "        target.append(3)\n",
    "    elif ((negative_df['labeled_class'][i] == 'negative') & (negative_df['actual_class'][i] == 'd')):\n",
    "        target.append(4)\n",
    "    else:\n",
    "        print('Error!')\n",
    "negative_df['target'] = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the postive and negative data frames to one ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = positive_df.merge(negative_df,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[['review','target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are only intrested in review and target columns , subset the data ignoring other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We had a king deluxe room for 2 nights. We res...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Swisshotel is awesome. Very high class. It...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Having had a great stay at the Monaco last Fal...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simply a nice place to stay... I had a great d...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stayed here October 31 through November 5 for ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target\n",
       "0  We had a king deluxe room for 2 nights. We res...     2.0\n",
       "1  The Swisshotel is awesome. Very high class. It...     2.0\n",
       "2  Having had a great stay at the Monaco last Fal...     2.0\n",
       "3  Simply a nice place to stay... I had a great d...     2.0\n",
       "4  Stayed here October 31 through November 5 for ...     2.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    400\n",
       "3.0    400\n",
       "2.0    400\n",
       "1.0    400\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Since all the class are equally distributed there is no need of using any sampling techniques. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us discuss the functionality of **extract_tokens** : \n",
    "\n",
    "- word_tokenize converts each review into lowercase and append each character of review into a list\n",
    "- the we tag parts of speech of each word and lemmatize the words(reduce the word to root as in dictionary format)\n",
    "- apped  these lists to a column names reviews_tokenized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_tokens(df):\n",
    "    review_tokenized = []\n",
    "    lmt = WordNetLemmatizer()\n",
    "    for index, datapoint in df.iterrows():\n",
    "        tokenize_words = word_tokenize(datapoint[\"review\"].lower(),language='english')\n",
    "        pos_word = pos_tag(tokenize_words)\n",
    "        tokenize_words = [\"_\".join([lmt.lemmatize(i[0]),i[1]]) for i in pos_word if (i[0] not in stopwords.words(\"english\") and len(i[0]) > 2)]\n",
    "        review_tokenized.append(tokenize_words)\n",
    "    df[\"review_tokenized\"] = review_tokenized\n",
    "    return df\n",
    "\n",
    "data = extract_tokens(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "      <th>review_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We had a king deluxe room for 2 nights. We res...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[king_NN, deluxe_NN, room_NN, night_NNS, reser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Swisshotel is awesome. Very high class. It...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[swisshotel_NN, awesome_JJ, high_JJ, class_NN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Having had a great stay at the Monaco last Fal...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[great_JJ, stay_NN, monaco_NN, last_JJ, fall_N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simply a nice place to stay... I had a great d...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[simply_RB, nice_JJ, place_NN, stay_VB, ..._:,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stayed here October 31 through November 5 for ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[stayed_VBN, october_JJ, november_JJ, cconfere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target  \\\n",
       "0  We had a king deluxe room for 2 nights. We res...     2.0   \n",
       "1  The Swisshotel is awesome. Very high class. It...     2.0   \n",
       "2  Having had a great stay at the Monaco last Fal...     2.0   \n",
       "3  Simply a nice place to stay... I had a great d...     2.0   \n",
       "4  Stayed here October 31 through November 5 for ...     2.0   \n",
       "\n",
       "                                    review_tokenized  \n",
       "0  [king_NN, deluxe_NN, room_NN, night_NNS, reser...  \n",
       "1  [swisshotel_NN, awesome_JJ, high_JJ, class_NN,...  \n",
       "2  [great_JJ, stay_NN, monaco_NN, last_JJ, fall_N...  \n",
       "3  [simply_RB, nice_JJ, place_NN, stay_VB, ..._:,...  \n",
       "4  [stayed_VBN, october_JJ, november_JJ, cconfere...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used gensim to deal with the semantics of reviews\n",
    "- corpara.Dictonary creates a corpus of review_tokenised column\n",
    "- then we filter the words which have occured in less than 2 documents and have occured more than 0.8 times(fraction of corpus size)\n",
    "- then we create a bag of words model of this corpus\n",
    "- and condense the corpus to sparse form \n",
    "- shape of corpus can be seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 5911)\n"
     ]
    }
   ],
   "source": [
    "from gensim import matutils,corpora, models\n",
    "\n",
    "def vectorize_comments(df):\n",
    "    d = corpora.Dictionary(df[\"review_tokenized\"])\n",
    "    d.filter_extremes(no_below=2, no_above=0.8)\n",
    "    d.compactify()\n",
    "    corpus = [d.doc2bow(text) for text in df[\"review_tokenized\"]]\n",
    "    corpus = matutils.corpus2csc(corpus, num_terms=len(d.token2id))\n",
    "    corpus = corpus.transpose()\n",
    "    return d, corpus\n",
    "\n",
    "dictionary,corpus = vectorize_comments(data)\n",
    "print (corpus.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Firstly ** we have train a Random forest Classifier using Grid Search CV with the parameters shown below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_rfc(X,y):\n",
    "    n_estimators = [100]\n",
    "    min_samples_split = [2]\n",
    "    min_samples_leaf = [1]\n",
    "    bootstrap = [True]\n",
    "    parameters = {'n_estimators': n_estimators, 'min_samples_leaf': min_samples_leaf,\n",
    "                  'min_samples_split': min_samples_split}\n",
    "    clf = GridSearchCV(RandomForestClassifier(verbose=1,n_jobs=-1), cv=4, param_grid=parameters)\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used 70% of data for training and 30% of data for testing and we have used 4-fold cross validation, On accessing the accuracy :\n",
    "- Accuracy of RF on Cross validation data is 69% and \n",
    "- Accuracy of RF on Cross validation data is ~ 72%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RF on CV sets :0.7017857142857142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(corpus, data[\"target\"], test_size=0.3, random_state=2016)\n",
    "rfc_clf = train_rfc(X_train,y_train)\n",
    "print (\"Accuracy of RF on CV sets :{}\".format(rfc_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RF on test sets is : 0.69375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of RF on test sets is : {}\".format(rfc_clf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the next option we have used Support Vector Machine Classifier along with GridSearchCV with penalty parameters of 10,15,20,25 . \n",
    "- Accuracy of RF on Cross validation data is ~ 74% and\n",
    "- Accuracy of RF on Cross validation data is 76% ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_svm(X,y):\n",
    "    parameters = {'C': [10,15,20,25],'random_state':[2016]}\n",
    "    clf = GridSearchCV(SVC(), cv=4, param_grid=parameters)\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy of SVM on CV sets :0.7392857142857143\n",
      "Accuracy of SVM on test sets is : 0.7604166666666666\n"
     ]
    }
   ],
   "source": [
    "svc_clf = train_svm(X_train,y_train)\n",
    "print(\"Best accuracy of SVM on CV sets :{}\".format(svc_clf.best_score_))\n",
    "print(\"Accuracy of SVM on test sets is : {}\".format(svc_clf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If make some tweaks we might be successful in increasing the accuarcy a little bit, but remember our dataset is ** very small ** (only 1600 reviews) , so there is a good chance that the model overfits the data and doesn't do well on new data \n",
    "\n",
    "** In this case a greater accuracy is bad, if we make attempts to increase the accuracy, since the dataset is very small the accuracy might increase but the model behaves badly on classifying new reviews . So for now let us stop here and use the SVC for classifying a review **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_test(review):\n",
    "    a = svc_clf.predict(review)\n",
    "    if a == 1.0 :\n",
    "        return('Fake Review (Positive)')\n",
    "    elif a == 2.0:\n",
    "        return('True Review (Positive)')\n",
    "    elif a == 3.0:\n",
    "        return('True Review (Negative)')\n",
    "    else :\n",
    "        return('Fake Review (Negative)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just for fun let us predict the class of some reviews in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Review (Negative)\n",
      "\n",
      "True Review (Positive)\n",
      "\n",
      "True Review (Negative)\n",
      "\n",
      "True Review (Positive)\n",
      "\n",
      "Fake Review (Positive)\n",
      "\n",
      "True Review (Positive)\n",
      "\n",
      "True Review (Negative)\n",
      "\n",
      "Fake Review (Negative)\n",
      "\n",
      "Fake Review (Negative)\n",
      "\n",
      "True Review (Negative)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in X_test[:10]:\n",
    "    print(model_test(i))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any Questions or Suggestions ?? \n",
    "\n",
    "Ping me @ **chaitanyadeva96@gmail.com **"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
